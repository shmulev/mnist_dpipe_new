import os
from functools import partial
from urllib.request import urlretrieve

from torch import nn
import numpy as np
import torch
from sklearn.metrics import accuracy_score, precision_score, recall_score

from dpipe.batch_iter.simple import load_combine
from dpipe.commands import predict, evaluate_aggregated_metrics
from dpipe.config import if_missing
from dpipe.experiment import flat
from dpipe.io import ConsoleArguments, load_json
from dpipe.layers import identity
from dpipe.split import get_cv_111
from dpipe.torch import TorchModel
from dpipe.train import train
from dpipe.train.logging import TBLogger
from dpipe.train.lr_policy import LearningRatePolicy

from mnist.resources import MNIST, CNN


# Data
def download_mnist(data_path):
    download = lambda filename: urlretrieve('http://yann.lecun.com/exdb/mnist/' + filename,
                                            os.path.join(data_path, filename))
    return [
        os.makedirs(data_path, exist_ok=True),
        download('train-images-idx3-ubyte.gz'),
        download('train-labels-idx1-ubyte.gz')
    ]


mnist_data_path = os.path.expanduser('~/mnist_data')
dataset = MNIST(mnist_data_path)

# experiment
split = get_cv_111(ids=dataset.ids, n_splits=3, val_size=0)

console = ConsoleArguments()
build_experiment = (
    if_missing(download_mnist, mnist_data_path),
    flat(config_path=console.config_path, experiment_path=console.experiment_path, split=split)
)

train_ids = load_json('train_ids.json')
val_ids = load_json('val_ids.json')
test_ids = load_json('test_ids.json')

# model training

model = TorchModel(
    CNN(), logits2pred=identity, logits2loss=nn.NLLLoss(), optimize=torch.optim.Adam)

batch_iter = load_combine(
    ids=train_ids, load_x=dataset.load_image, load_y=dataset.load_label, batch_size=100, shuffle=True)

train_model = train(
    do_train_step=model.do_train_step, batch_iter=batch_iter, n_epochs=40, lr_policy=LearningRatePolicy(1e-3),
    logger=TBLogger('train_logs'))

predict_object = lambda img: np.argmax(model.do_inf_step(img[None])[0], axis=1)

metrics = {
    'precision': partial(precision_score, average='weighted'),
    'recall': partial(recall_score, average='weighted'),
    'accuracy': accuracy_score
}

run_experiment = (
    if_missing(lambda path: [train_model, model.save(path)], path='model.pth'),

    if_missing(partial(
        predict, ids=test_ids, load_x=dataset.load_image, predict_fn=predict_object), output_path='test_predictions'),
    evaluate_aggregated_metrics(dataset.load_label, metrics, 'test_predictions', 'test_metrics')
)
