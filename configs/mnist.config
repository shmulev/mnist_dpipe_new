import os
from functools import partial
from urllib.request import urlretrieve

from torch import nn
import numpy as np
import torch
from sklearn.metrics import accuracy_score, precision_score, recall_score

from dpipe.batch_iter import make_infinite_batch_iter
from dpipe.batch_iter.sources import load_by_random_id
from dpipe.commands import predict, evaluate_aggregated_metrics
from dpipe.config import if_missing
from dpipe.experiment import flat
from dpipe.io import ConsoleArguments, load_json
from dpipe.layers import identity
from dpipe.split import train_val_test_split
from dpipe.torch import TorchModel
from dpipe.train import train
from dpipe.train.logging import TBLogger
from dpipe.train.policy import Constant, NEpochs

from mnist.resources import MNIST, CNN


# Data
def download_mnist(data_path):
    download = lambda filename: urlretrieve('http://yann.lecun.com/exdb/mnist/' + filename,
                                            os.path.join(data_path, filename))
    return [
        os.makedirs(data_path, exist_ok=True),
        download('train-images-idx3-ubyte.gz'),
        download('train-labels-idx1-ubyte.gz')
    ]


mnist_data_path = os.path.expanduser('~/mnist_data')
dataset = MNIST(mnist_data_path)

# experiment
split = train_val_test_split(ids=dataset.ids, n_splits=3, val_size=0)

console = ConsoleArguments()
build_experiment = (
    if_missing(download_mnist, mnist_data_path),
    flat(config_path=console.config_path, experiment_path=console.experiment_path, split=split)
)

train_ids = load_json('train_ids.json')
val_ids = load_json('val_ids.json')
test_ids = load_json('test_ids.json')

# model training

model = TorchModel(
    CNN(), logits2pred=identity, logits2loss=nn.NLLLoss(), optimize=torch.optim.Adam)

BATCH_SIZE = 512
batch_iter = make_infinite_batch_iter(
    load_by_random_id(dataset.load_image, dataset.load_label, ids = train_ids),
    batch_size = BATCH_SIZE,
    n_iters_per_epoch = len(train_ids) // BATCH_SIZE
)

train_model = train(
    do_train_step=model.do_train_step,
    batch_iter=batch_iter,
    logger=TBLogger('train_logs'),
    lr=Constant(1e-3),
    n_epochs = NEpochs(40))

predict_object = lambda img: np.argmax(model.do_inf_step(img[None]), axis=1)

metrics = {
    'precision': partial(precision_score, average='weighted'),
    'recall': partial(recall_score, average='weighted'),
    'accuracy': accuracy_score
}

run_experiment = (
    if_missing(lambda path: [train_model, model.save(path)], path='model.pth'),

    if_missing(partial(
        predict, ids=test_ids, load_x=dataset.load_image, predict_fn=predict_object), output_path='test_predictions'),
    evaluate_aggregated_metrics(dataset.load_label, metrics, 'test_predictions', 'test_metrics')
)

